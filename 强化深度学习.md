# 强化学习
## 强化学习基础概念
1. 基础概念：State(状态)，Action(动作)，Agent(动作是谁做的，谁就是agent)，policy(根据观测的状态做出决策)，Reward(奖励)
**Policy Function**(概率密度函数)：Π(a|s) = P(A = a|S = s)
**State Transition**(状态转移)：旧状态通过Action转移到新状态。p(s'|s,a)
2. Agent和环境交互：Agent看到状态S~t~，做出动作a~t~，更新状态S~t+1~，环境给Agent奖励r~t~。
**Return**:U~t~ = R~t~ + R~t+1~ +...(累计未来奖励)。
**Discounted Return**：折扣回报，U~t~ = R~t~ + γR~t+1~ + γ^2^R~t+2~ + ...，其中γ是折扣率(权重)
如果已知S~t~，则U~t~取决于A~t~及以后的动作及S~t+1~及以后的状态。对U~t~求期望，记Q~Π~ = E(U~t~|S~t~ = s~t~,A~t~ = a~t~)为**动作价值函数**，Q~Π~可判断做出动作A是否明智。
**最优动作价值函数**：取Q* = max~Π~Q~Π~(s~t~, a~t~)
**状态价值函数**：取V~Π~ = E~A~[Q~Π~(s~t~, A)]，可以判断当前局势的好坏。
eg:(gym库)
```
import gym
from warnings import filterwarnings
filterwarnings(action='ignore', category=DeprecationWarning, message='`np.bool8` is a deprecated alias')

env = gym.make('CartPole-v1',render_mode='rgb_array')
state = env.reset()

for t in range(100):
    env.render()
    print(state)

    action = env.action_space.sample()
    [state, reward, done, Abool, info] = env.step(action)

    if done:
        print('finished')
        break
env.close()
```

## 价值学习
学习一个函数来近似Q*，从而有a* = argmaxQ*。
**Deep Q Network**(DQN)：利用神经网络Q(s, a; w)近似Q*(s, a)。
**Temporal Difference Learning**(时间差分算法)
1. 做出预测：例如令q = Q(w) = 1000
2. 完成过程，得到目标(target)y = 860
3. 定义损失L = 1/2(q - y)^2^
4. 计算梯度dL/dw = (q - y)dQ(w)/dw
5. 利用梯度下降法：w~t+1~ = w~t~ - αdL/dw

此外，可以完成部分过程y = 300，估计剩余过程Q(w) = 600，则q - y = 100。
类比到DQN中，有：Q(s~t~,a~t~;w) = r~t~ + γQ(s~t+1~,a~t+1~;w)，y~t~ = r~t~ + γmaxQ*(s~t+1~,a~t~;w)。

## 策略学习
用神经网络(策略网络)Π(a|s;θ)近似Π(a|s)，θ为参数。
利用V(s|θ) = ΣΠ(a|s;θ)*Q~Π~(s,a)，记J(θ) = E~s~[V(S;θ)]，改进θ使J(θ)尽可能大。
步骤：
1. 观察状态s
2. 利用梯度上升更新θ，θ -> θ+βdV(s;θ)/dθ
其中梯度的求法为：dV/dθ = E~A~[d(lnΠ(A|s;θ))/dθ * Q~Π~(s, A)] （假设Q与θ独立）

**蒙特卡洛近似**：
 随机从Π中抽样得到a'，计算g(a',θ) = d(lnΠ(a'|s;θ))/dθ * Q~Π~(s, a')，其中g(a',θ)为梯度的无偏估计，用其做近似即可。

**Actor-Critic**：其中actor为policy network，critic为value network。故V~Π~(s) = Σ~A~Π(a|s;θ)*q(s,a;w) = V(s;θ,w)
步骤：
1. 观察s~t~
2. 随机从Π中抽样出a~t~
3. 执行a~t~，得到s~t+1~和r~t~
4. 用TD算法更新w
5. 用policy gradient更新θ

**Policy Gradient with Baseline**：
取baseline: δ~t~ = q~t~ - (r~t~ + γ*q~t+1~)，则θ可更新为θ+αδ~t~dV/dθ
其它baseline(取为V(s~t~))：A(s~t~,a~t~) = Q(s~t~,a~t~) - V(s~t~) = r~t+1~ + γV(s~t+1~) - V(s~t~)

## TD算法
Q~Π~(s~t~,a~t~) = E[U~t~|s~t~,a~t~] = E[R~t~ + γU~t+1~|s~t~,a~t~] = E[R~t~|s~t~,a~t~] + γE[U~t+1~|s~t~,a~t~]，又Q~Π~(S~t+1~,A~t+1~) = E[U~t~+1|s~t~,a~t~]，得：
Q~Π~(s~t~,a~t~) = E[R~t~ + γQ~Π~(S~t+1~,A~t+1~)]，利用蒙特卡洛近似，得E[R~t~] = r~t~，整体接近于y~t~，TD算法让Q~Π~接近于y~t~。
**Sarsa算法**：
1. 观测(s~t~,a~t~,r~t~,s~t+1~)
2. 从Π中采样a~t+1~
3. TD target y~t~ = r~t~ + γQ~Π~(s~t+1~,a~t+1~)
4. 计算TD error δ~t~ = Q~Π~(s~t~,a~t~) - y~t~
5. 定义Loss函数为δ~t~^2^/2
6. 计算梯度d(δ~t~^2^)/dw = δ~t~dQ/dw
7. 用梯度下降法更新参数w

**Q-Learning算法**：
参考前文策略学习，神经网络近似Q*

**Multi-Step TD Target**:
利用U~t~的递归式，有U~t~ = Σ~i=0~^m-1^γ^i^R~t+1~ + γ^m^U~t+m~，从而可知y~t~ = Σ~i=0~^m-1^γ^i^r~t+1~ + γ^m^Q~Π~(s~t+m~,a~t+m~)

## 连续控制
连续控制的action space是连续的，有无穷多个动作。
**确定策略梯度(DPG)**:
Deterministic Actor-Critic:给定状态s，，通过策略网络输出一个确定的动作a(不同于之前输出概率分布Π(a|s))。例如二轴机械臂，运动空间为二维，则输出的a为二维，且包含无穷多个动作。
定义DPG：g = d(q(s,Π(s;θ);w))/dθ = da/dθ * dq/da，用梯度上升θ + βg更新θ。

### 置信域策略优化(TRPO)
取N(θ~old~)为θ~old~的一个邻域，N(θ) = {||θ - θ~old~|| < Δ}。利用L(θ|θ~old~)近似邻域里的J(θ)，则N(θ)称为置信域。则转换为使L最大化。
V~Π~(s) = Σ~a~Π(a|s;θ~old~) * Π(a|s;θ)/Π(a|s;θ~old~) * Q~Π~(s,a) = E~A~(Π(A|s;θ)/Π(A|s;θ~old~) * Q~Π~(s,A))
于是J(θ) = E~s~(V~Π~(S)) = E~s~(E~A~)
取L(θ|θ~old~) = 1/n * ΣΠ(a~i~|s~i~;θ)/Π(a~i~|s~i~;θ~old~) * Q~Π~(s~i~,a~i~)。其中用观测值u~i~近似Q~i~

### 近端策略优化(PPO)
**on-policy和off-policy**: on-policy只使用当前正在优化的policy生成的数据进行训练，当用(s,a,r,s)数据更新policy的参数后，需要用它再生成新数据进行训练。

PPO中取L~PPO~(θ|θ~old~) = L(θ|θ~old~) - βKL(θ,θ~old~)。其中KL散度用来判断θ和θ~old~之间的距离。

PPO2中，J~PPO2~ = Σmin(ΣΠ(a~i~|s~i~;θ)/Π(a~i~|s~i~;θ~old~) * Q~Π~(s~i~,a~i~), clip(ΣΠ(a~i~|s~i~;θ)/Π(a~i~|s~i~;θ~old~), 1-ε, 1+ε) * Q~Π~(s~i~,a~i~))。其中clip(x,y,z)表示x小于y则取y，x大于z则取z，x在yz间则取x。
（训练Π和V神经网络）

## 神经网络
**稠密层(Dense Layer)**:每个输入都与每个输出相连，也称全连接层。

## Pybullet仿真
流程：强化学习算法和虚拟环境(gym)建立联系，虚拟环境和物理引擎(Pybullet)建立联系。
### 创建gym环境
基本架构：
```
import gym
from gym import error,spaces,utils
from gym.utils import seeding

import os
import pybullet as p
import pybullet_data
import math
import numpy as np
import random

class PandaEnv(gym.Env):
    metadata = {'render.modes':['human']}
    def __init__(self):
        ...
    def step(self,action):
        ...
    def reset(self):
        ...
    def render(self,mode='human'):
        ...
    def close(self):
        ...
```
1. init函数
使用pybullet的GUI显示模式pybullet.connect(pybullet.GUI)，再添加相机resetDebugVisualizeCaamera()
Gym环境中有action_space和observation_space，其中observation是[夹爪1 夹爪2 x y z]五元素数组，action为[x y z 手指位置]四元素数组
```
def __init__(self):
        p.connect(p.GUI)
        p.resetDebugVisualizerCamera(cameraDistance=1.5,cameraYaw=0,\
                                     cameraPitch=-40,cameraTargetPosition=[0.55,-0.35,0.2])
        self.action_space=spaces.Box(np.array([-1]*4),np.array([1]*4))
        self.observation_space=spaces.Box(np.array([-1]*5),np.array([1]*5))
```
同时init函数还包括摄像头相关设置，运动范围相关设置
```
#设置x，y，z方向的observation的范围
self.x_low_obs = 0.2
self.x_high_obs = 0.7
self.y_low_obs = -0.3
self.y_high_obs = 0.3
self.z_low_obs = 0
self.z_high_obs = 0.55

# 设置x，y，z方向的action范围
self.x_low_action = -0.4
self.x_high_action = 0.4
self.y_low_action = -0.4
self.y_high_action = 0.4
self.z_low_action = -0.6
self.z_high_action = 0.3

self.step_counter = 0

# 设置关节运动的上限，下限，范围，初始位姿等
self.urdf_root_path = pybullet_data.getDataPath()
# lower limits for null space
self.lower_limits = [-.967, -2, -2.96, 0.19, -2.96, -2.09, -3.05]
# upper limits for null space
self.upper_limits = [.967, 2, 2.96, 2.29, 2.96, 2.09, 3.05]
# joint ranges for null space
self.joint_ranges = [5.8, 4, 5.8, 4, 5.8, 4, 6]
# restposes for null space
self.rest_poses = [0, 0, 0, 0.5 * math.pi, 0, -math.pi * 0.5 * 0.66, 0]
# joint damping coefficents
self.joint_damping = [
    0.00001, 0.00001, 0.00001, 0.00001, 0.00001, 0.00001, 0.00001
]

self.init_joint_positions = [
    0.006418, 0.413184, -0.011401, -1.589317, 0.005379, 1.137684,
    -0.006539
]

self.orientation = p.getQuaternionFromEuler(
    [0., -math.pi, math.pi / 2.])

# 相机参数设置
self.camera_parameters = {
    'width': 960.,
    'height': 720,
    'fov': 60,
    # 相机能看到的最近距离
    'near': 0.1,
    # 最远距离
    'far': 100.,
    # 相机位置
    'eye_position': [0.59, 0, 0.8],
    相机视角位置
    'target_position': [0.55, 0, 0.05],
    'camera_up_vector':
                [1, 0, 0],  # I really do not know the parameter's effect.
    'light_direction': [
        0.5, 0, 1
    ],  # the direction is from the light source position to the origin of the world frame.
}

# 确定相机视角矩阵
self.view_matrix = p.computeViewMatrixFromYawPitchRoll(
    cameraTargetPosition=[0.55, 0, 0.05],
    distance=.7,
    yaw=90,
    pitch=-70,
    roll=0,
    upAxisIndex=2)

# 确定相机投影矩阵
self.projection_matrix = p.computeProjectionMatrixFOV(
    fov=self.camera_parameters['fov'],
    aspect=self.camera_parameters['width'] /
            self.camera_parameters['height'],
    nearVal=self.camera_parameters['near'],
    farVal=self.camera_parameters['far'])

# 添加自己的光源
p.configureDebugVisualizer(lightPosition=[5, 0, 5])
p.resetDebugVisualizerCamera(cameraDistance=1.5,
                                cameraYaw=0,
                                cameraPitch=-40,
                                cameraTargetPosition=[0.55, -0.35, 0.2])
```
2. reset函数
用于机械臂复位，场景重置，相机图像传回，加载模型，指示工作区线条等。
```
def _reset(self):
    # 重置环境的时间步，步数为n表示每n步进行一个动作
    self.step_counter = 0

    p.resetSimulation()
    # p.configureDebugVisualizer(p.COV_ENABLE_RENDERING, 0)
    self.terminated = False
    # 设置重力
    p.setGravity(0, 0, -10)

    # 这些是周围那些白线，用来观察是否超过了obs的边界
    p.addUserDebugLine(
        lineFromXYZ=[self.x_low_obs, self.y_low_obs, 0],
        lineToXYZ=[self.x_low_obs, self.y_low_obs, self.z_high_obs])
    p.addUserDebugLine(
        lineFromXYZ=[self.x_low_obs, self.y_high_obs, 0],
        lineToXYZ=[self.x_low_obs, self.y_high_obs, self.z_high_obs])
    p.addUserDebugLine(
        lineFromXYZ=[self.x_high_obs, self.y_low_obs, 0],
        lineToXYZ=[self.x_high_obs, self.y_low_obs, self.z_high_obs])
    p.addUserDebugLine(
        lineFromXYZ=[self.x_high_obs, self.y_high_obs, 0],
        lineToXYZ=[self.x_high_obs, self.y_high_obs, self.z_high_obs])

    p.addUserDebugLine(
        lineFromXYZ=[self.x_low_obs, self.y_low_obs, self.z_high_obs],
        lineToXYZ=[self.x_high_obs, self.y_low_obs, self.z_high_obs])
    p.addUserDebugLine(
        lineFromXYZ=[self.x_low_obs, self.y_high_obs, self.z_high_obs],
        lineToXYZ=[self.x_high_obs, self.y_high_obs, self.z_high_obs])
    p.addUserDebugLine(
        lineFromXYZ=[self.x_low_obs, self.y_low_obs, self.z_high_obs],
        lineToXYZ=[self.x_low_obs, self.y_high_obs, self.z_high_obs])
    p.addUserDebugLine(
        lineFromXYZ=[self.x_high_obs, self.y_low_obs, self.z_high_obs],
        lineToXYZ=[self.x_high_obs, self.y_high_obs, self.z_high_obs])
    
    # 加载模型
    p.setAdditionalSearchPath(pybullet_data.getDataPath())
    p.loadURDF("plane.urdf",basePosition=[0, 0, -0.65])
    self.kuka_id = p.loadURDF("kuka_iiwa/model.urdf",useFixedBase=True)
    table_uid = p.loadURDF("table/table.urdf",basePosition=[0.5, 0, -0.65])
    p.changeVisualShape(table_uid, -1, rgbaColor=[1, 1, 1, 1])
    self.object_id = p.loadURDF("random_urdfs/000/000.urdf",
                                basePosition=[
                                    random.uniform(self.x_low_obs,
                                                    self.x_high_obs),
                                    random.uniform(self.y_low_obs,
                                                    self.y_high_obs), 0.01
                                ])
    
    # 使机械臂到初始位姿
    self.num_joints = p.getNumJoints(self.kuka_id)

    for i in range(self.num_joints):
        p.resetJointState(
            self.kuka_id,
            jointIndex=i,
            targetValue=self.init_joint_positions[i],
        )

    self.robot_pos_obs = p.getLinkState(self.kuka_id,
                                        self.num_joints - 1)[4]
    
    # 重置后进行一次仿真，更新状态
    p.stepSimulation()
    
    # 获取相机图像信息
    # px包括R，G，B，Alpha通道，alpha为透明度
    (_, _, px, _,
        _) = p.getCameraImage(width=960,
                               height=960,
                               viewMatrix=self.view_matrix,
                               projectionMatrix=self.projection_matrix,
                               renderer=p.ER_BULLET_HARDWARE_OPENGL)
    self.images = px

    p.enableJointForceTorqueSensor(bodyUniqueId=self.kuka_id,
                                    jointIndex=self.num_joints - 1,
                                    enableSensor=True)

    self.object_pos = p.getBasePositionAndOrientation(self.object_id)[0]
    
    # the 4th channel is alpha channel, we do not need it.
    self.images = self.images[:, :, :
                                    3]  
    
    # process_image函数对图像进行处理
    return self._process_image(self.images)
```
其中图像处理函数为
```
def _process_image(self, image):
    """Convert the RGB pic to gray pic and add a channel 1

    if image is not None:
        image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        # 其中None的作用是添加一个批次维度，转换为四维数组
        image = cv2.resize(image, (self.kImageSize['width'], self.kImageSize['height']))[None, :, :]
        # np.array返回图像的channel，宽与高
        return np.array(image, dtype=np.uint8)
    else:
        return np.zeros((1, self.kImageSize['width'], self.kImageSize['height']), dtype=np.uint8)
```
再将内部的_reset方法封装
```
def reset(self):
    state = self._reset()
    # step中的多个state集合成一个数组，并增加一个维度
    states = np.concatenate([state for _ in range(self.skip)], 0)[None, :, :, :]
    # 对图像进行数据增强，并删除单维度
    return np.squeeze(self.random_crop(states,self.kFinalImageSize['width']))
```
利用crop进行数据增强
```
def random_crop(self, imgs: np.ndarray, out: int) -> np.ndarray:
    n, c, h, w = imgs.shape
    crop_max = h - out + 1
    w1 = np.random.randint(0, crop_max, n)
    h1 = np.random.randint(0, crop_max, n)
    cropped = np.empty((n, c, out, out), dtype=np.uint8)
    for i, (img, w11, h11) in enumerate(zip(imgs, w1, h1)):
        cropped[i] = img[:, h11:h11 + out, w11:w11 + out]
    return cropped
```
3. step函数
定义机械臂末端移动增量，计算逆解，控制机械臂移动，获取环境奖励和图像信息
```
def _step(self, action: np.float32):
    dv = 0.1
    dx = action[0] * dv
    dy = action[1] * dv
    dz = action[2] * dv
    
    # 获取当前坐标和action后的新坐标
    self.current_pos = p.getLinkState(self.kuka_id, self.num_joints - 1)[4]
    self.new_robot_pos = [
        self.current_pos[0] + dx, self.current_pos[1] + dy,
        self.current_pos[2] + dz
    ]
    # 计算逆解
    self.robot_joint_positions = p.calculateInverseKinematics(
        bodyUniqueId=self.kuka_id,
        endEffectorLinkIndex=self.num_joints - 1,
        targetPosition=[
            self.new_robot_pos[0], self.new_robot_pos[1],
            self.new_robot_pos[2]
        ],
        targetOrientation=self.orientation,
        jointDamping=self.joint_damping,
        )
    for i in range(self.num_joints):
        p.resetJointState(
            self.kuka_id,
            jointIndex=i,
            targetValue=self.robot_joint_positions[i],
        )
    p.stepSimulation()

    # 在代码开始部分，如果定义了is_good_view，那么机械臂的动作会变慢，方便观察
    if self.is_good_view:
        time.sleep(0.05)

    self.step_counter += 1

    return self._reward()
```
其中_reward的设定为：
```
def _reward(self):

    # 一定注意是取第4个值，请参考pybullet手册的这个函数返回值的说明
    # getLinkState[4]返回末端位置信息
    self.robot_state = p.getLinkState(self.kuka_id, self.num_joints - 1)[4]

    self.object_state = np.array(
        p.getBasePositionAndOrientation(self.object_id)[0]).astype(
        np.float32)

    square_dx = (self.robot_state[0] - self.object_state[0]) ** 2
    square_dy = (self.robot_state[1] - self.object_state[1]) ** 2
    square_dz = (self.robot_state[2] - self.object_state[2]) ** 2

    # 用机械臂末端和物体的距离作为奖励函数的依据
    self.distance = sqrt(square_dx + square_dy + square_dz)

    x = self.robot_state[0]
    y = self.robot_state[1]
    z = self.robot_state[2]

    # 如果机械臂末端超过了obs的空间，也视为done，而且会给予一定的惩罚
    terminated = bool(x < self.x_low_obs or x > self.x_high_obs
                        or y < self.y_low_obs or y > self.y_high_obs
                        or z < self.z_low_obs or z > self.z_high_obs)

    if terminated:
        reward = -0.1
        self.terminated = True

    # 如果机械臂一直无所事事，在最大步数还不能接触到物体，也需要给一定的惩罚
    elif self.step_counter > self.kMaxEpisodeSteps:
        reward = -0.1
        self.terminated = True

    elif self.distance < 0.1:
        reward = 1
        self.terminated = True
    else:
        reward = 0
        self.terminated = False
    
    # 获取图像信息
    (_, _, px, _,
        _) = p.getCameraImage(width=960,
                               height=960,
                               viewMatrix=self.view_matrix,
                               projectionMatrix=self.projection_matrix,
                               renderer=p.ER_BULLET_HARDWARE_OPENGL)
    self.images = px
    self.processed_image = self._process_image(self.images)
    return self.processed_image, reward, self.terminated, {}
```
再对_step()进行封装，_step可以理解成一个时间步做的action，step则是一个skip做的action
```
def step(self, action: np.float32) -> Tuple[np.ndarray, float, bool, any]
    logger.debug(f'action={action}')
    total_reward = 0
    states = []
    state, reward, done, info = self._step(action)
    for i in range(self.skip):
        if not done:
            state, reward, done, info = self._step(action)
            total_reward += reward
            states.append(state)
        else:
            states.append(state)
    states = np.concatenate(states, 0)[None, :, :, :]
    logger.debug(f'total_reward={total_reward}')
    return np.squeeze(self.random_crop(states,self.kFinalImageSize['width'])), total_reward, done,{}
```
4. render函数

### 采用Stable Baselines3库
**重写SB3的一些方法**：
1. 重写特征提取的方法
```
class CustomCNN(BaseFeaturesExtractor):

    def __init__(self, observation_space: gym.spaces.Box, features_dim: int = 256):
        super(CustomCNN, self).__init__(observation_space, features_dim)
        # We assume CxHxW images (channels first)
        # Re-ordering will be done by pre-preprocessing or wrapper
        n_input_channels = observation_space.shape[0]
        self.cnn = nn.Sequential(
            nn.Conv2d(n_input_channels, 32, kernel_size=3, stride=2, padding=1),
            nn.ReLU(),
            nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=1),
            nn.ReLU(),
            nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=1),
            nn.ReLU(),
            nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=1),
            nn.ReLU(),

            nn.Flatten(),
        )

        # Compute shape by doing one forward pass
        with th.no_grad():
            n_flatten = self.cnn(
                th.as_tensor(observation_space.sample()[None]).float()
            ).shape[1]

        self.linear = nn.Sequential(nn.Linear(n_flatten, features_dim), nn.ReLU())

    def forward(self, observations: th.Tensor) -> th.Tensor:
        return self.linear(self.cnn(observations))
``` 

## Pytorch使用
### 基本训练步骤
**eg1**.以线性回归y = Xw + b + ε为例
1. 建立数据集
2. 读取数据集
3. 初始化模型参数
4. 定义模型
5. 定义损失函数
6. 定义优化算法
7. 训练
代码实现:
```
import math
import matplotlib
import numpy as np
import torch
import random
from d2l import torch as d2l

#建立数据集
def synthetic_data(w, b, num_examples):
    X = torch.normal(0, 1, (num_examples, len(w)))
    y = torch.matmul(X, w) + b
    y += torch.normal(0, 0.01, y.shape)
    return X, y.reshape((-1, 1))

#通过随机抽样抽取一批次的样本用于训练
def data_iter(batch_size, features, labels):
    num_examples = len(features)
    indices = list(range(num_examples))
    random.shuffle(indices)
    for i in range(0, num_examples, batch_size):
        batch_indices = torch.tensor(
            indices[i: min(i + batch_size, num_examples)]
        )
        yield features[batch_indices], labels[batch_indices]

#定义模型
def linreg(X, w, b):
    return torch.matmul(X, w) + b

#定义损失函数
def squared_loss(y_hat, y):
    return (y_hat - y.reshape(y_hat.shape))**2 / 2

#定义优化算法,利用参数的梯度下降法
def sgd(params, lr, batch_size):
    with torch.no_grad():
        for param in params:
            param -= lr * param.grad / batch_size
            param.grad.zero_()

true_w = torch.tensor([2, -3.4])
true_b = 4.2
features, labels = synthetic_data(true_w, true_b, 1000)

#待训练的w和b值
w = torch.normal(0, 0.01, size=(2,1), requires_grad=True)
b = torch.zeros(1, requires_grad=True)
#lr为学习率,num_epochs为迭代次数
lr = 0.03
num_epochs = 3
net = linreg
loss = squared_loss
batch_size = 10

for epoch in range(num_epochs):
    for X, y in data_iter(batch_size, features, labels):
        l = loss(net(X, w, b), y)
        #对损失求和,通过反向传播计算模型梯度
        #梯度存在参数w和b中
        l.sum().backward()
        sgd([w, b], lr, batch_size)
    with torch.no_grad():
        train_l = loss(net(features, w, b), labels)
        print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')
```
**注意**:
1. 创建张量,设置required_grad为True时,程序会自动追踪所有对于该张量的操作, 调用.backward()计算所有的梯度,累计到grad()

### 简化流程
1. 读取数据集(利用torch.utils中的data类)
```
def load_array(data_arrays, batch_size, is_train=True):
    dataset = data.TensorDataset(*data_arrays)
    return data.DataLoader(dataset, batch_size, shuffle=is_train)
```
TensorDataset接受tensor类型,dataloader通过dataset创建迭代器

2. 定义模型(利用torch的nn类)
```
net = nn.Sequential(nn.Linear(2, 1))
```

3. 初始化模型参数
net[0]访问第一层,weight.data和bias.data访问权重和偏置的张量数据
```
net[0].weight.data.normal_(0, 0.01)
net[0].bias.data.fill_(0)
```

4. 定义损失函数(采用nn的平方L2范数)
```
loss = nn.MSELoss()
```
5. 定义优化算法(采用torch的optim库)
```
trainer = torch.optim.
```
6. 优化
```
num_epochs = 3
for epoch in range(num_epochs):
    for X,y in data_iter:
        l = loss(net(X), y)
        trainer.zero_grad()
        l.backward()
        #通过trainer.step()更新参数
        trainer.step()
    l = loss(net(features), labels)
    print(f'epoch {epoch + 1}, loss {1:f}')
```

### Softmax回归
一个单层线性回归，每个输出o1，o2，o3取决于输入x1，x2，x3，向量形式为o = wx + b。全连接层的参数开销为O(dq)，且可以减少到O(dq/n)，其中n为超参数。

#### softmax运算
令y' = softmax(o)，其中y'~j~ = exp(o~j~)/Σexp(o~k~)，因此y可以视作一个概率分布，argmaxy'~j~ = argmaxo~j~。

#### 损失函数
y可以视作对给定任意输入x的每个类的条件概率，如y1 = P(y = 猫 | x)，假设一共有n个样本，索引i的样本由特征向量x~i~和独热标签y~i~组成。
P(Y|X) = ΠP(y~i~|x~i~)，最大化P(Y|X)即可最小化负对数似然-logP(Y|X) = Σ-logP(y~i~|x~i~) = Σl(y~i~, y')，其中l为损失函数，定义为l = -Σy~j~logy'~j~
对损失函数求导得dl(y, y') = softmax(o)~j~ - y~j~，即观测值与估计值之间的差异。

#### 图像分类数据集
1. 读取数据集(Fashion-MNIST)
```
d2l.use_svg_display()

trans = transforms.ToTensor()
mnist_train = torchvision.datasets.FashionMNIST(
    root="../data", train=True, transform=trans, download=True
)
mnist_test = torchvision.datasets.FashionMNIST(
    root="../data", train=False, transform=trans, download=True
)


def get_fashion_mnist_labels(labels):
    text_labels = ['t-shirt', 'trousers', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker',
                   'bag', 'ankle boot']
    return[text_labels[int(i)] for i in labels]


def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5):
    figsize = (num_cols * scale, num_rows * scale)
    # d2l.plt.subplots调用matplotlib绘制子图
    _, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize)
    axes = axes.flatten()
    for i, (ax, img) in enumerate(zip(axes, imgs)):
        if torch.is_tensor(img):
            ax.imshow(img.numpy())
        else:
            ax.imshow(img)
        # 隐藏轴上的刻度标签
        ax.axes.get_xaxis().set_visible(False)
        ax.axes.get_yaxis().set_visible(False)
        if titles:
            ax.set_title(titles[i])
    return axes

# 固定读取数据的用法
X, y = next(iter(data.DataLoader(mnist_train, batch_size=18)))
show_images(X.reshape(18, 28, 28), 2, 9, titles=get_fashion_mnist_labels(y))
```
或者用内置的数据迭代器：
```
def get_dataloader_workers():
    return 4

train_iter = data.DataLoader(mnist_train, batch_size, shuffle=True, num_workers=get_dataloader_workers())
```

#### Softmax实现
1. 初始化模型参数
```
num_inputs = 784
num_outputs = 10

W = torch.normal(0, 0.01, size=(num_inputs, num_outputs), requires_grad=True)
```
2. 定义softmax操作
```
def softmax(X):
    X_exp = torch.exp(X)
    # 对X_exp的行求和
    partition = X_exp.sum(1, keepdim=True)
    return X_exp / partition
```
3. 定义模型(Y = WX + b)
```
def net(X):
    return softmax(torch.matmul(X.reshape((-1, W.shape[0])), W) + b)
```
4. 定义损失函数(交叉熵)
```
def cross_entropy(y_hat, y):
    return -torch.log(y_hat[range(len(y_hat)), y])
```
5. 分类精度
当给定预测概率分布y'，输出硬预测时，通常选择概率最高的类。分类精度即正确预测数量与总预测数量之比。
```
# 计算正确预测的数量
def accuracy(y_hat, y):
    if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:
        y_hat = y_hat.argmax(axis=1)
    cmp = y_hat.type(y.dtype) == y
    return float(cmp.type(y.dtype()).sum())
```
同时对于任意数据迭代器data_iter可访问的数据集，可以评估任意模型net的精度
```
def evaluate_accuracy(net, data_iter):
    # 检查net是否是Module类的实例
    if isinstance(net, torch.nn.Module):
        # 设为评估模式，不进行梯度计算
        net.eval()
    # 创建Accumulator类，有两个对象进行累加
    metric = Accumulator(2)
    with torch.no_grad():
        for X, y in data_iter:
            metric.add(accuracy(net(X), y), y.numel())
    return metric[0] / metric[1]
```
其中Accumulator类用于相加和获取编号：
```
class Accumulator:
    def __init__(self, n):
        self.data = [0.0] * n

    def add(self, *args):
        self.data = [a + float(b) for a, b in zip(self.data, args)]

    def reset(self):
        self.data = [0.0] * len(self.data)

    def __getitem__(self, idx):
        return self.data(idx)
```
6. 训练
其中updater是更新模型参数常用的函数，接受批量大小为参数，可以是d2l.sgd函数
```
def train_epoch_ch3(net, train_iter, updater):
    if isinstance(net, torch.nn.Module):
        net.train()
    # 训练损失总和，训练准确度总和，样本数
    metric = Accumulator(3)
    for X, y in train_iter:
        # 计算准确度，更新参数
        y_hat = net(X)
        l = cross_entropy(y_hat, y)
        # 判断updater是否为优化算法
        if isinstance(updater, torch.optim.Optimizer):
            # 清空updater梯度
            updater.zero_grad()
            l.mean().backward()
            updater.step()
        else:
            # 采用自定义更新函数updater
            l.sum().backward()
            updater(X.shape[0])
        metric.add(float(l.sum()), accuracy(y_hat, y), y.numel())
    return metric[0] / metric[2], metric[1] / metric[2]
```
集成训练函数，运行多个迭代周期
```
def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater):
    for epoch in range(num_epochs):
        animator = Animator()
        train_metrics = train_epoch_ch3(net, train_iter, loss, updater)
        test_acc = evaluate_accuracy(net, test_iter)
        animator.add(epoch + 1, train_metrics + (test_acc, ))
    train_loss, train_acc = train_metrics
    assert train_loss < 0.5, train_loss
    assert train_acc <= 1 and train_acc > 0.7, train_acc
    assert test_acc <= 1 and test_acc > 0.7, test_acc
```
#### Softmax简洁实现
对于softmax函数，y'~j~ = exp(o~j~)/Σexp(o~k~) = exp(o~j~ - max(o~k~))exp(max(o~k~))/Σexp(o~k~ - max(o~k~))exp(max(o~k~)) = exp(o~j~ - max(o~k~))/Σexp(o~k~ - max(o~k~))，当计算指数函数时，由于计算交叉熵损失会取对数，可以将softmax与交叉熵结合。即直接使用o~j~ - max(o~k~)。
```
loss = nn.CrossEntropyLoss(redunction='none')
```
完整流程：
```
import torch
from IPython import display
from torch import nn
from d2l import torch as d2l

batch_size = 256
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)

net = nn.Sequential(nn.Flatten(), nn.Linear(784, 10))

def init_weights(m):
    if type(m) == nn.Linear:
        nn.init.normal_(m.weight, std=0.01)

# apply将函数fn递归地应用到模块自身
# 常用于初始化参数
net.apply(init_weights)
loss = nn.CrossEntropyLoss(reduction='none')
trainer = torch.optim.SGD(net.parameters(), lr=0.1)

num_epochs = 10
d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)
```
其中**nn.Flatten()**将连续维度范围展平为张量，得到tensor类型数据。

### 多层感知机
由多层神经元组成，每一层与上一层相连接受输入，也与下一层相连。

#### 隐藏层
可以在网络中加入一个或多个隐藏层，克服线性模型限制，使其能处理更普遍的函数关系。可以将许多全连接层堆叠在一起，每一层输出到上面的层，直到输出。

用H表示隐藏层输出，O表示多层感知机输出，则：H = σ(XW1 + b1), O = HW2 + b2 = (XW1 + b1)W2 + b2 = XW1W2 + b1W2 + b2 = XW + b，其中σ为非线性的激活函数

**激活函数**:
* 修正线性单元ReLU(x) = max(x, 0)
* sigmoid函数sigmoid(x) = 1/1 + exp(-x)，将输入压缩到(0, 1)中
*  tanh函数tanh(x) = 1 - exp(-2x)/1 + exp(-2x)

#### 多层感知机的实现
1. 初始化模型参数
假设为单隐藏层，有256个隐藏单元
```
W1 = nn.Parameter(torch.randn(
    num_inputs, num_hiddens, requires_grad=True) * 0.01)
b1 = nn.Parameter(torch.zeros(num_hiddens, requires_grad=True))
W2 = nn.Parameter(torch.randn(
    num_hiddens, num_outputs, requires_grad=True) * 0.01)
b2 = nn.Parameter(torch.zeros(num_outputs, requires_grad=True))
```
2. 激活函数
```
def relu(X):
    a = torch.zeros_like(X)
    return torch.max(X, a)
```
3. 模型
```
def net(X):
    # 将二维图像转化为长度为num_inputs的向量
    X = X.reshape((-1, num_inputs))
    H = relu(X@W1 + b1)
    return (H@W2 + b2)
```
4. 损失函数
```
loss = CrossEntropyLoss(reduction='none')
```
5. 训练
```
num_epochs, lr = 10, 0.1
updater = torch.optim.SGD(params, lr=lr)
d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, updater)
```

#### 多层感知机简洁实现
```
net = nn.Sequential(nn.Flatten(),
                    nn.Linear(784, 256),
                    nn.ReLU(),
                    nn.Linear(256, 10))

def init_weights(m):
    if type(m) == nn.Linear:
        nn.init.normal_(m.weight, std=0.01)

net.apply(init_weights)

batch_size, lr, num_epochs = 256, 0.1, 10
loss = nn.CrossEntropyLoss(reduction='none')
trainer = torch.optim.SGD(net.parameters(), lr=lr)
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)
d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)
d2l.plt.show()
```

### 模型选择
**过拟合**：模型在训练数据上的拟合比在潜在分布中更接近。用正则化对抗过拟合。

**训练误差**：模型在训练数据集上得到的误差。
**泛化误差**：模型应用在从原始样本分布中抽取的无限多数据样本时，模型误差的期望

**K折交叉验证**：原始训练数据被分为K个不重叠子集，在K-1个子集上训练，在剩余的⼀个⼦集上进⾏验证。最后通过对K次实验的结果取平均来估计训练和验证误差。

#### 多项式回归
假定用y = 5 + 1.2x - 3.4x^2^/2! + 5.6x^3^/3! + ε生成训练和测试数据标签（ε服从均值为0，标准差为0.1的正态分布）
1. 生成数据集
```
max_degree = 20
n_train, n_test = 100, 100
true_w = np.zeros(max_degree)
true_w[0:4] = np.array([5, 1.2, -3.4, 5.6])

features = np.random.normal(size=(n_train + n_test, 1))
np.random.shuffle(features)
# np.power用于对features求多项式
# power传入的第二个参数为0到19的数组
poly_features = np.power(features, np.arange(max_degree).reshape(1, -1))
for i in range(max_degree):
    poly_features[:,1] /= math.gamma(i + 1)
# 多项式标签与真实权重点积得到真实标签
labels = np.dot(poly_features, true_w)
# 带噪声的标签
labels += np.random.normal(scale=0.1, size=labels.shape)
# 将ndarray转化为tensor
true_w, features, poly_features, labels = [torch.tensor(x, dtype=torch.float32)
                                           for x in [true_w, features, poly_features, labels]]
```
2. 定义损失函数
```
def evaluate_loss(net, data_iter, loss):
    # 损失总和。样本数量
    metric = d2l.Accumulator(2)
    for X, y in data_iter:
        out = net(X)
        y = y.reshape(out.shape)
        l = loss(out, y)
        metric.add(l.sum(), l.numel())
    return metric[0] / metric[1]
```
3. 定义训练函数
```
def train(train_features, test_features, train_labels, test_labels, num_epochs=400):
    loss = nn.MSELoss(reduction='none')
    input_shape = train_features.shape[-1]
    # 不设置偏置
    net = nn.Sequential(nn.Linear(input_shape, 1, bias=False))
    batch_size = min(10, train_labels.shape[0])
    # load_array创建迭代器，通常要将标签转化为列向量
    train_iter = d2l.load_array((train_features, train_labels.reshape(-1, 1)),
                                batch_size)
    test_iter = d2l.load_array((test_features, test_labels.reshape(-1, 1)),
                               batch_size, is_train=False)
    trainer = torch.optim.SGD(net.parameters(), lr=0.01)
    animator = d2l.Animator(xlabel='epoch', ylabel='loss', yscale='log',
                            xlim=[1, num_epochs], ylim=[1e-3, 1e2], 
                            legend=['train', 'test'])
    for epoch in range(num_epochs):
        d2l.train_epoch_ch3(net, train_iter, loss, trainer)
        if epoch == 0 or (epoch + 1) % 20 == 0:
            animator.add(epoch + 1, (evaluate_loss(net, train_iter, loss),
                        evaluate_loss(net, test_iter, loss)))
    print('weight', net[0].weight.data.numpy())
```
4. 训练
```
train(poly_features[:n_train, :2], poly_features[n_train:, :2],
      labels[:n_train], labels[n_train:])
```
其中poly_features[:n_train, :2]表示从开始到n_train-1，0到2列，后者表示从n_train到结尾。

**小结**：
1. evaluate_loss函数接受包含X和标签y的迭代器，以及网络net，损失函数loss，计算损失。
2. d2l.Animator函数创建一个animator对象，可以实现加法操作

#### 权重衰减
通过函数与0的距离来衡量函数复杂度。一种方法是将线性函数f(x) = w^T^x中的权重向量的某个范数(例如||w||^2^)作为惩罚项加到最小化损失问题中。
迭代更新的形式由w - ε/BΣdl(w,b)改为：
**(1 - ελ)w - ε/BΣx~i~(w^T^x~i~ + b - y~i~)**，根据估计值与观测值之间的差异更新w。

例子：**高维线性回归**：根据y = 0.05 + Σ0.01x~i~ + ε
1. 生成数据
```
n_train, n_test, num_inputs, batch_size = 20, 100, 200, 5
true_w, true_b = torch.ones((num_inputs, 1)) * 0.01, 0.05
# synthetic_data函数用于合成数据，生成X，由w和b生成y
train_data = d2l.synthetic_data(true_w, true_b, n_train)
train_iter = d2l.load_array(train_data, batch_size)
test_data = d2l.synthetic_data(true_w, true_b, n_test)
test_iter = d2l.load_array(test_data, batch_size, is_train=False)
```
2. 初始化模型参数
```
def init_params():
    w = torch.normal(0, 1, size=(num_inputs, 1), requires_grad=True)
    b = torch.zeros(1, requires_grad=True)
    return [w, b]
```
3. 定义L2范数惩罚
```
def l2_penalty(w):
    return torch.sum(w.pow(2)) / 2
```
4. 定义训练代码
```
def train(lambd):
    w, b = init_params()
    # d2l.linreg为线性回归函数
    # 通过lambda将函数赋给net，loss
    net, loss = lambda X: d2l.linreg(X, w, b), d2l.squared_loss 
    animator = d2l.Animator(xlabel='epochs', ylabel='loss',yscale='log',
            xlim=[5, num_epochs], legend=['train', 'test'])
    
    for epoch in range(num_epochs):
        for X, y in train_iter:
            l = loss(net(X), y) + lambd * l2_penalty(w)
            l.sum().backward()
            d2l.sgd([w, b], lr, batch_size)
        if (epoch + 1) % 5 == 0
            animator.add(epoch + 1, (d2l.evaluate_loss(net, train_iter, loss),
            d2l.evaluate_loss(net, test_iter, loss)))
```
**简洁实现**：实例化优化器时直接通过weight_dacay指定超参数
```
def train_concise(wd):
    net = nn.Sequential(nn.Linear(num_inputs, 1))
    for param in net.parameters():
        param.data.normal_():
    loss = nn.MSELoss(reduction='none')
    num_epochs, lr = 100, 0.003
    # 偏置参数没有衰减
    trainer = torch.optim.SGD([
        {"params":net[0].weight,'weight_decay': wd},
        {"params":net[0].bias}], lr=lr)
    animator = d2l.Animator(xlabel='epochs',                                   ylabel='loss', yscale='log',
        xlim=[5, num_epochs], legend=['train', 'test'])
    for epoch in range(num_epochs):
        for X, y in train_iter:
            trainer.zero_grad()
            l = loss(net(X), y)
            l.mean().backward()
            trainer.step()
        if (epoch + 1) % 5 == 0:
            animator.add(epoch + 1,
                (d2l.evaluate_loss(net, train_iter, loss),
                d2l.evaluate_loss(net, test_iter, loss)))
    print('w的L2范数：', net[0].weight.norm().item())
```

#### 暂退法
暂退法在前向传播的过程中，计算每一内部层的同时注入噪声。在标准暂退法正则化中，每个中间值h以暂退概率p由随机变量h' = h / 1-p替换，并保证E(h') = h
实现：
```
def dropout_layer(X, dropout):
    assert 0 <= dropout  <= 1
    # 所有元素都丢弃
    if dropout == 1:
        return torch.zeros_like(X)
    if dropout == 0:
        return X
    # 当torch.rand(X.shape)对应位置大于dropout时置1
    mask = (torch.rand(X.shape) > dropout).float()
    return mask * X / (1.0 - dropout)
```
模型示例（两个隐藏层）：
```
class Net(nn.Module):
    def __init__(self, num_inputs, num_outputs, num_hiddens1, num_hiddens2, is_training = True):
        super(Net, self).__init__()
        self.num_inputs = num_inputs
        self.training = is_trianing
        self.lin1 = nn.Linear(num_inputs, num_hiddens1)
        self.lin2 = nn.Linear(num_hiddens1, num_hiddens2)
        self.lin3 = nn.Linear(num_hiddens2, num_outputs)
        self.relu = nn.ReLU()

    def forward(self, X):
        # 第一个隐藏层输出H1
        H1 = self.relu(self.lin1(X.reshape((-1, self.num_inputs))))
        # 训练模型时才使用dropout
        if self.training == True:
            H1 = dropout_layer(H1, dropout1)
        H2 = self.relu(self.lin2(H1))
        if self.training == True:
            H2 = dropout_layer(H2, dropout2)
        out = self.lin3(H2)
        return out
```
**简洁实现**：
```
net = nn.Sequential(nn.Flatten(),
                    nn.Linear(784, 256),
                    nn.ReLU(),
                    nn.Dropout(dropout1),
                    nn.Linear(256, 256),
                    nn.ReLU(),
                    nn.Dropout(dropout2),
                    nn.Linear(256, 10))

def init_weights(m):
    if type(m) == nn.Linear:
        nn.init.normal_(m.weight, std=0.01)
net.apply(init_weights)
```

### 前向传播/反向传播
* 前向传播：按顺序计算和存储神经网络中每层的结果
* 反向传播：根据微积分中的链式规则，按相反顺序从输出层到输入层遍历网络，存储了参数的偏导数。

#### 梯度消失
考虑具有L层，输入x输出o，h^l^ = f~l~(h^l-1^), o = f~L~ * f~L-1~...f~1~(x)，对任一组参数w~l~求导可写为d~hL-1~h^L^...d~hl~h^l+1^ * d~wl~h~l~，乘积可能很小或很大。不稳定梯度会威胁算法的稳定性。

例如sigmoid函数，当输入很大或很小时，它们的梯度都会消失。

#### 参数初始化
* Xavier初始化：假设全连接层输出o~i~，对于n~in~输入x~j~及权重w~ij~，输出为o~i~ = Σw~ij~x~j~。w~ij~从统一分布中独立抽取，假设分布均值为0，方差σ^2^。假设x~j~也具有0均值和方差γ^2^，可求得E(o~i~) = 0, Var(o~i~) = n~in~σ^2^γ^2^。Xavier初始化从0均值，σ^2^ = 2/n~in~ + n~out~的高斯分布中采样权重。

### 环境和分布偏移
* 协变量偏移：输入的分布随时间而改变，而标签函数P(y|x)没有改变。（eg：卡通猫狗和真实猫狗）
* 标签偏移：类别条件分布P(x|y)在不同领域保持不变，但标签边缘概率P(y)不变。（eg：疾病的流行率会改变，得病后患者症状不变）
* 概念偏移

#### 分布偏移纠正
* 经验风险最小化：minimize 1/nΣl(f(x~i~), y~i~)
* 协变量偏移纠正：评估p(y|x)，然而有些x是从q(x)中得来，但p(y|x) = q(y|x)有恒等式：l(f(x), y)p(y|x)p(x)dxdy = l(f(x), y)q(y|x)q(x)p(x)/q(x)dxdy，利用p(x)/q(x)重新衡量样本权重β，将权重β代入到经验风险最小化来训练模型。

### 综合案例之一
房价预测：
```
import hashlib
import os
import tarfile
import zipfile
import requests
import numpy as np
import pandas as pd
import torch
from torch import nn
from d2l import torch as d2l

# 下载，缓存数据集
DATA_HUB = dict()
DATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/'

# 下载数据集，缓存在本地目录并返回文件名
def download(name, cache_dir=os.path.join('..', 'data')):
    assert name in DATA_HUB, f"{name} 不存在于 {DATA_HUB}"
    # sha1_hash为验证文件完整性的哈希密钥
    url, sha1_hash = DATA_HUB[name]
    # 创建缓存目录
    os.makedirs(cache_dir, exist_ok=True)
    # 将url的/后最后一部分名字与cache_dir拼接
    fname = os.path.join(cache_dir, url.split('/')[-1])
    if os.path.exists(fname):
        # 创建sha1对象
        # update(data)更新sha1的值，hexdigest获取值
        sha1 = hashlib.sha1()
        # 读取fname文件，'rb'为只读
        with open(fname, 'rb') as f:
            while True:
                # 读取1Mb数据
                data = f.read(1048576)
                if not data:
                    break
                sha1.update(data)
        if sha1.hexdigest() == sha1_hash:
            return fname
    print(f'正在从{url}下载{fname}...')
    # 下载url的内容
    r = requests.get(url, stream=True, verify=True)
    with open(fname, 'wb') as f:
        f.write(r.content)
    return fname

# 下载并解压缩zip或tar文件
def download_extract(name, folder=None):
    fname = download(name)
    # 获取fname的父目录
    base_dir = os.path.dirname(fname)
    # 获取文件名和文件扩展名
    data_dir, ext = os.path.splitext(fname)
    if ext == '.zip':
        # 创建Zipfile对象fp，r表示只读
        fp = zipfile.ZipFile(fname, 'r')
    elif ext in ('.tar', '.gz'):
        fp = tarfile.open(fname, 'r')
    else:
        assert False
    fp.extractall(base_dir)
    return os.path.join(base_dir, folder) if folder else data_dir

def download_all():
    for name in DATA_HUB:
        download(name)

DATA_HUB['kaggle_house_train'] = ( #@save
DATA_URL + 'kaggle_house_pred_train.csv',
'585e9cc93e70b39160e7921475f9bcd7d31219ce')
DATA_HUB['kaggle_house_test'] = ( #@save
DATA_URL + 'kaggle_house_pred_test.csv',
'fa19780a7b011d9b009e8bff8e99922a8ee2eb90')

# read_csv读取csv并转化为pandas数据帧
#数据帧每一行代表一个数据，一列代表一个特征
train_data = pd.read_csv(download('kaggle_house_train'))
test_data = pd.read_csv(download('kaggle_house_test'))

# 用iloc进行数据帧的索引
print(train_data.iloc[0:4, [0, 1, 2, 3, 4, 5, 6]])
# 用concat进行合并
all_features = pd.concat((train_data.iloc[:, 1:-1], test_data.iloc[:, 1:]))

# 数据预处理
# dtypes返回包含每个列的数据类型的序列
numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index
all_features[numeric_features] = all_features[numeric_features].apply(
    lambda x: (x - x.mean()) / (x.std()))
# fillna(0)对缺失值赋值0
all_features[numeric_features] = all_features[numeric_features].fillna(0)

# get_dummies将离散特征进行独热编码
# dummy_na指定给缺失值创建新的二进制特征列，1表示缺失
all_features = pd.get_dummies(all_features, dummy_na=True)

n_train = train_data.shape[0]
# values将pandas格式转化为numpy
train_features = torch.tensor(all_features[:n_train].values, dtype=torch.float32)
test_features = torch.tensor(all_features[n_train:].value, dtype=torch.float32)
train_labels = torch.tensor(
    train_data.SalePrice.values.reshape(-1, 1), dtype=torch.float32)

# 训练
loss = nn.MSELoss()
in_features = train_features.shape[1]

def get_net():
    net = nn.Sequential(nn.Linear(in_features,1))
    return net

# 误差指标为|logy - logy'| < δ
def log_rmse(net, features, labels):
    # 将小于1的值设置为1
    clipped_preds = torch.clamp(net(features), 1, float('inf'))
    rmse = torch.sqrt(loss(torch.log(clipped_preds), torch.log(labels)))
    # item转化为标量
    return rmse.item()

def train(net, train_features, train_labels, test_features, test_labels,
          num_epochs, learning_rate, weight_decay, batch_size):
    train_ls, test_ls=[], []
    train_iter = d2l.load_array((train_features, train_labels), batch_size)
    # 使用Adam优化算法
    optimizer = torch.optim.Adam(net.parameters(),
                                 lr = learning_rate,
                                 weight_decay= weight_decay)
    for epoch in range(num_epochs):
        for X, y in train_iter:
            l = loss(net(X), y)
            l.backward()
            optimizer.step()
        train_ls.append(log_rmse(net, train_features, train_labels))
        if test_labels is not None:
            test_ls.append(log_rmse(net, test_features, test_labels))
    return train_ls, test_ls

# k折交叉验证
def get_k_fold_data(k, i, X, y):
    assert k > 1
    fold_size = X.shape[0] // k
    X_train, y_train = None, None
    for j in range(k):
        idx = slice(j * fold_size, (j + 1) * fold_size)
        X_part, y_part = X[idx, :], y[idx]
        if j == 1:
            X_valid, y_valid = X_part, y_part
        # 如果训练集为空，将其添加到训练集上
        elif X_train is None:
            X_train, y_train = X_part, y_part
        # 利用cat函数对训练集拼接
        else:
            X_train = torch.cat([X_train, X_part], 0)
            y_train = torch.cat([y_train, y_part], 0)
    return X_train, y_train, X_valid, y_valid

# 训练k次后返回训练和验证误差的平均值
def k_fold(k, X_train, y_train, num_epochs, learning_rate, weight_decay,
           batch_size):
    train_l_sum, valid_l_sum = 0, 0
    for i in range(k):
        data = get_k_fold_data(k, i, X_train, y_train)
        net = get_net()
        train_ls, valid_ls = train(net, *data, num_epochs, learning_rate,
                                   weight_decay, batch_size)
        train_l_sum += train_ls[-1]
        valid_l_sum += valid_ls[-1]
    return train_l_sum / k, valid_l_sum / k
```
**主要流程**：
1. 下载并读取数据集
2. 数据预处理（获取是数字特征的列，进行预处理，对不是数字特征的采用独热编码，划分训练集和测试集）
3. 定义网络，误差和训练过程
4. 定义验证过程（k折交叉验证，并返回训练，验证误差均值）